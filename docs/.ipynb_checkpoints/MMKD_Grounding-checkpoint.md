# ğŸ“Œ MMKD-RL-Grounding è¿è¡Œæ•™ç¨‹  MMKD-RL-Grounding Usage Tutorial

æœ¬é¡¹ç›®åŸºäº **GRPOï¼ˆGroup Relative Policy Optimizationï¼‰** å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äº **Qwen2.5-VL-Instruct** è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ï¼Œ**å•ç›®æ ‡æ£€æµ‹æ¡†å®šä½ä»»åŠ¡ï¼ˆSingle-box Groundingï¼‰** å’Œ **å¤šç›®æ ‡æ£€æµ‹æ¡†å®šä½ä»»åŠ¡ï¼ˆMulti-box Groundingï¼‰** ä¸Šçš„ä¼˜åŒ–ã€‚  
This project is based on the **GRPO (Group Relative Policy Optimization)** reinforcement learning framework and is designed to optimize the **Qwen2.5-VL-Instruct** vision-language model for **single-box grounding** and **multi-box grounding** tasks.

---

## ğŸ“ é¡¹ç›®ç»“æ„  Project Structure

```
.
â”œâ”€â”€ result/                         # è®­ç»ƒè¾“å‡ºç›®å½•
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ mmkd_rl_grounding.json      # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/
â”‚   â””â”€â”€ multi_box_grounding.yaml    # æ•°æ®é›†é…ç½®
â”œâ”€â”€ easydistill/mmkd
â”‚   â””â”€â”€ mmkd_rl_grounding.py        # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ docs
â”‚   â””â”€â”€ mmkd_grounding.md           # æœ¬æ–‡æ¡£
```

- `result/`ï¼šè®­ç»ƒè¾“å‡ºç›®å½•  
  `result/`: Training output directory  
- `configs/`ï¼šåŒ…å«ä¸»è¦é…ç½®æ–‡ä»¶  
  `configs/`: Contains primary config files  
- `data/`ï¼šæ•°æ®é›†åŠå…¶é…ç½®æ–‡ä»¶  
  `data/`: Dataset and configuration files  
- `easydistill/mmkd/`ï¼šä¸»è¦è®­ç»ƒè„šæœ¬  
  `easydistill/mmkd/`: Main training script  
- `docs/`ï¼šæœ¬æ•™ç¨‹æ–‡æ¡£  
  `docs/`: This documentation file  

---

## ğŸš€ å¿«é€Ÿå¼€å§‹  Quick Start

### 1. å‡†å¤‡æ•°æ®  Prepare Data

- æ•°æ®é›†æ ¼å¼æ”¯æŒ `.json`  
  The dataset supports `.json` format  
- æ£€æµ‹æ¡†æ ¼å¼ $[x_{min},y_{min},x_{max},y_{max}]$  
  Detection box format $[x_{min},y_{min},x_{max},y_{max}]$  
- æ¯æ¡æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š  
  Each data entry format is as follows:

```json
[
    {
        "image_path": "345.jpg",
        "height": 720,
        "width": 1280,
        "instruction": "Draw bounding boxes around product positions and label them with tags 0, 1, 2, 3, then output in JSON format",
        "abs_box": {
            "0": [[456,337,725,557]],
            "1": [],
            "2": [[849,407,961,482],[965,480,1099,550]],
            "3": []
        }
    },
    ...
]
```

> âš ï¸ **å¯¹äºä»…éœ€è¦å•æ¡†æ£€æµ‹çš„åœºæ™¯ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼çš„jsonï¼Œå¹¶è¢«é…ç½®å•æ¡†æ£€æµ‹çš„å¥–åŠ±å‡½æ•°ã€‚**  
> âš ï¸ **For single-box detection, please use the following format and configure single-box reward functions.**

```json
[
    {
        "image_path": "APP_20250815_103045.png",
        "height": 1080,
        "width": 1920,
        "instruction": "è¯·å¸®æˆ‘æ‰¾å‡ºåŒ…å«â€œç«‹å³é¢†å–â€æŒ‰é’®çš„åŒºåŸŸï¼Œè¾“å‡ºå…¶åæ ‡ï¼Œæ ¼å¼ä¸º [x_min, y_min, x_max, y_max]ã€‚",
        "bbox": [850, 720, 1070, 780]
    }
    ...
]
```

- æ•°æ®é›†é…ç½®æ–‡ä»¶ `data/multi_box_grounding.yaml` ç¤ºä¾‹ï¼š  
  Example configuration file `data/multi_box_grounding.yaml`:

```yaml
datasets:
  - json_path: "data/multi_box_grounding_RL_sample.json"
    sampling_strategy: "all" # or "first:100", "random:50%", "end:10" 
```

---

### 2. é…ç½®è®­ç»ƒå‚æ•°  Configure Training Parameters

ç¼–è¾‘é…ç½®æ–‡ä»¶ `configs/mmkd_rl_grounding.json`ï¼š  
Edit the configuration file `configs/mmkd_rl_grounding.json`:

```json
{
  "job_type": "mmkd_rl_grounding",
  "dataset": {
    "labeled_path": "data/multi_box_grounding.yaml"
  },
  "models": {
    "student": "Qwen/Qwen2.5-VL-3B-Instruct"
  },
  "training": {
    "reward_funcs": [
      "multi_box_format_reward",
      "multi_gaussian_point",
      "multi_gaussian_plane_reward"
    ],
    "deepspeed": "configs/accelerate_config/stage3.json",
    "output_dir": "./result/",
    "max_length": 4096,
    "num_train_epochs": 1,
    "per_device_train_batch_size": 8,
    "roll_out_num": 8,
    "save_steps": 400,
    "logging_steps": 4,
    "learning_rate": 1e-6,
    "max_pixels": 12845056
  }
}
```

---

### 3. å¯åŠ¨è®­ç»ƒ  Launch Training

ä½¿ç”¨ `easydistill` å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š  
Start training using the `easydistill` command:

```bash
easydistill --config configs/mmkd_rl_grounding.json
```

---

## ğŸ¯ å¥–åŠ±å‡½æ•°è¯´æ˜  Reward Function Explanation

| å¥–åŠ±å‡½æ•°å                     | é€‚ç”¨åœºæ™¯ | ä½œç”¨è¯´æ˜          |
| ------------------------- | ---- | ------------- |
| `multi_box_format_reward` | å¤šæ¡†æ£€æµ‹ | æ ¡éªŒè¾“å‡ºæ ¼å¼æ˜¯å¦ä¸ºåˆæ³•åˆ—è¡¨ |
| `multi_gaussian_point`    | å¤šæ¡†æ£€æµ‹ | åŸºäºä¸­å¿ƒç‚¹çš„é«˜æ–¯å¥–åŠ±    |
| `multi_gaussian_plane`    | å¤šæ¡†æ£€æµ‹ | åŸºäºæ•´ä¸ªæ¡†çš„é«˜æ–¯å¥–åŠ±    |
| `format`                  | å•æ¡†æ£€æµ‹ | æ ¡éªŒè¾“å‡ºæ ¼å¼æ˜¯å¦ä¸ºåˆæ³•åˆ—è¡¨ |
| `gaussian_point`          | å•æ¡†æ£€æµ‹ | åŸºäºä¸­å¿ƒç‚¹çš„é«˜æ–¯å¥–åŠ±    |
| `gaussian_plane`          | å•æ¡†æ£€æµ‹ | åŸºäºæ•´ä¸ªæ¡†çš„é«˜æ–¯å¥–åŠ±    |

| Reward Function            | Scenario      | Description                                   |
| ----------------------     | ------------ | --------------------------------------------- |
| `multi_box_format_reward`  | Multi-box     | Checks if output format is a valid list       |
| `multi_gaussian_point`     | Multi-box     | Gaussian reward based on center points        |
| `multi_gaussian_plane`     | Multi-box     | Gaussian reward based on whole box            |
| `format`                   | Single-box    | Validate output format is [x1, y1, x2, y2]    |
| `gaussian_point`           | Single-box    | Gaussian reward based on box center           |
| `gaussian_plane`           | Single-box    | Gaussian reward based on box coverage         |

> âš ï¸ **è¯·ç¡®ä¿æ¨¡å‹å¤§éƒ¨åˆ†å›ç­”çš„è¾“å‡ºæ ¼å¼æ¥è¿‘æ•°æ®é›†ä¸­çš„æ£€æµ‹æ¡†æ ¼å¼**  
> âš ï¸ **Please ensure your model output format matches the dataset bounding box format most of the time.**  
>> è¯·å…ˆä»¥ç›¸åŒæ ¼å¼å¾®è°ƒæ¨¡å‹ï¼Œå¦‚ `data/multi_box_grounding_SFT_sample.json` ä¸­çš„ç¤ºä¾‹ï¼Œæˆ–åœ¨ Prompt ä¸­è¦æ±‚æ¨¡å‹è¾“å‡ºç›¸åº”æ£€æµ‹æ¡†æ ¼å¼  
>> First, finetune the model to output the same format as in `data/multi_box_grounding_SFT_sample.json`, or require the format in the prompt.

---

å¥–åŠ±å‡½æ•°ä»‹ç»  
Reward Function Details

#### 1. é«˜æ–¯ç‚¹å¥–åŠ±ï¼ˆGaussian Point Rewardï¼‰

- **ä½œç”¨**ï¼šè¡¡é‡é¢„æµ‹ä¸­å¿ƒä¸ç›®æ ‡å…ƒç´ ä¸­å¿ƒçš„ç²¾ç¡®å¯¹é½ç¨‹åº¦ï¼Œé¼“åŠ±ç²¾ç¡®å®šä½ã€‚  
  **Purpose**: Measures the degree of alignment between predicted box center and ground truth center to encourage precise localization.
- **å…¬å¼**ï¼š  
  **Formula**:  
  $$R_{\text{point}} = \exp\left(-\frac{1}{2}\left(\frac{(c_x^p - c_x^{gt})^2}{\sigma_x^{gt^2}} + \frac{(c_y^p - c_y^{gt})^2}{\sigma_y^{gt^2}}\right)\right)$$

  - $$(c_x^p, c_y^p)$$ï¼šé¢„æµ‹æ¡†ä¸­å¿ƒåæ ‡  
    $$(c_x^p, c_y^p)$$: Predicted box center coordinates  
  - $$(c_x^{gt}, c_y^{gt})$$ï¼šçœŸå®æ¡†ä¸­å¿ƒåæ ‡  
    $$(c_x^{gt}, c_y^{gt})$$: Ground truth box center coordinates  
  - $$\sigma_x^{gt}, \sigma_y^{gt}$$ï¼šçœŸå®æ¡†é«˜æ–¯åˆ†å¸ƒåœ¨x/yæ–¹å‘çš„æ ‡å‡†å·®  
    $$\sigma_x^{gt}, \sigma_y^{gt}$$ï¼šStandard deviation in x/y direction for the ground truth box

---

#### 2. é«˜æ–¯è¦†ç›–å¥–åŠ±ï¼ˆGaussian Coverage Rewardï¼‰

- **ä½œç”¨**ï¼šè¯„ä¼°é¢„æµ‹é«˜æ–¯åˆ†å¸ƒä¸çœŸå®é«˜æ–¯åˆ†å¸ƒçš„ç©ºé—´é‡å ç¨‹åº¦ï¼Œç¡®ä¿åŒºåŸŸè¦†ç›–ã€‚  
  **Purpose**: Measures spatial overlap between predicted and ground-truth Gaussian distributions to ensure coverage.
- **å…¬å¼**ï¼ˆåŸºäºBhattacharyyaç³»æ•°ï¼‰ï¼š  
  **Formula** (based on Bhattacharyya coefficient):  
  $$R_{\text{coverage}} = \exp\left(-\frac{1}{8}(\mu_p - \mu_{gt})^T \Sigma^{-1} (\mu_p - \mu_{gt}) - \frac{1}{2} \ln\frac{|\Sigma|}{\sqrt{|\Sigma_p||\Sigma_{gt}|}}\right)$$
  
  - $$\mu_p, \mu_{gt}$$ï¼šé¢„æµ‹/çœŸå®åˆ†å¸ƒçš„å‡å€¼å‘é‡  
    $$\mu_p, \mu_{gt}$$: Mean vector of predicted / ground-truth distribution  
  - $$\Sigma_p, \Sigma_{gt}$$ï¼šé¢„æµ‹/çœŸå®åˆ†å¸ƒçš„åæ–¹å·®çŸ©é˜µ  
    $$\Sigma_p, \Sigma_{gt}$$: Covariance matrix of predicted / ground-truth distribution  
  - $$\Sigma = \frac{\Sigma_p + \Sigma_{gt}}{2}$$ï¼šå¹³å‡åæ–¹å·®çŸ©é˜µ  
    $$\Sigma = \frac{\Sigma_p + \Sigma_{gt}}{2}$$: Average covariance matrix

---

#### 3. æ ¼å¼å¥–åŠ±ï¼ˆFormat Rewardï¼‰ï¼ˆå¯é€‰ï¼‰  
#### 3. Format Reward (Optional)

- **ä½œç”¨**ï¼šç¡®ä¿æ¨¡å‹è¾“å‡ºçš„åæ ‡æ ¼å¼ä¸¥æ ¼ç¬¦åˆ `[x1,y1,x2,y2]` çš„å››æ•°å€¼æ ¼å¼ï¼Œé¿å…å› æ ¼å¼é”™è¯¯å¯¼è‡´ä»»åŠ¡å¤±è´¥ã€‚  
  **Purpose**: Ensures model output strictly matches the four-value `[x1, y1, x2, y2]` box format to avoid failures due to format errors.
- **å…¬å¼**ï¼ˆäºŒå…ƒå¥–åŠ±ï¼‰ï¼š  
  **Formula** (binary reward):  

  $$R_{\text{format}} = 1,  \text{è‹¥è¾“å‡ºç¬¦åˆæ£€æµ‹æ¡†æ ¼å¼} [x1,y1,x2,y2] ï¼Œ\text{å¦åˆ™} R_{\text{format}} = 0$$

---

å¦‚éœ€æ›´å¤šç»†èŠ‚è¯·å‚è€ƒæºä»£ç åŠç›¸å…³é…ç½®æ–‡ä»¶ã€‚  
For more details, please refer to the source code and related configuration files.

---
