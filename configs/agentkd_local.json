{
    "job_type": "agentkd_local",
    "dataset": {
        "instruction_path": "data/agent_demo.jsonl",
        "labeled_path_raw": "data/agent_demo_labeled_raw.jsonl",
        "labeled_path": "data/agent_demo_labeled.json"
    },
    "models": {
        "teacher": "Qwen/Qwen2.5-7B-Instruct",
        "student": "Qwen/Qwen2.5-7B-Instruct",
        "trust_remote_code": true
    },
    "inference":{
        "step_models": {
            "first_thought": {
            "name": "Qwen2.5-72B-Instruct",
            "max_tokens": 4096,
            "temperature": 0.5
            },
            "reasoning": {
            "name": "Qwen2.5-72B-Instruct",
            "max_tokens": 8192,
            "temperature": 0.7
            },
            "evaluation": {
            "name": "Qwen2.5-72B-Instruct",
            "max_tokens": 4096,
            "temperature": 0.3
            }
        },
        "prompts": {
            "REACT_SYSTEM_PROMPT": "\n  You are an expert assistant who can solve any task using code blobs. You will be given a task to solve as best you can.\n  To do so, you have been given access to a list of tools: these tools are basically Python functions which you can call with code.\n  To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Code:', and 'Observation:' sequences.\n\n  At each step, in the 'Thought:' sequence, you should first explain your reasoning towards solving the task and the tools that you want to use.\n  Then in the 'Code:' sequence, you should write the code in simple Python. The code sequence must write bewtween ```python and ```.\n  During each intermediate step, you can use 'print()' to save whatever important information you will then need.\n  These print outputs will then appear in the 'Observation:' field, which will be available as input for the next step.\n  In the end you have to return a final answer using the `final_answer_print` tool.\n  For math problems, if not specified, always return LaTex format as the final answer.\n\n  On top of performing computations in the Python code snippets that you create, you only have access to these tools:\n  - web_search: Provides a related search result from the web.\n  Takes inputs: {'query': {'type': 'any', 'description': 'The query to search.'}}\n  Returns an output of type: any\n  - final_answer_print: Provides a final answer to the given problem.\n  Takes inputs: {'answer': {'type': 'any', 'description': 'The final answer to the problem, it should be short and concise.'}}\n  Returns an output of type: any\n\n  Here are the rules you should always follow to solve your task:\n  1. Always provide a 'Thought:' sequence, and a 'Code:\\n```python' sequence ending with '```' sequence, else you will fail.\n  2. Use only variables that you have defined!\n  3. Always use the right arguments for the tools. DO NOT pass the arguments as a dict as in 'answer = wiki({'query': \"What is the place where James Bond lives?\"})', but use the arguments directly as in 'answer = wiki(\"What is the place where James Bond lives?\")'.\n  4. Take care to not chain too many sequential tool calls in the same code block, especially when the output format is unpredictable. For instance, a call to search has an unpredictable return format, so do not have another tool call that depends on its output in the same block: rather output results with print() to use them in the next block.\n  5. Call a tool only when needed, and never re-do a tool call that you previously did with the exact same parameters.\n  6. Don't name any new variable with the same name as a tool: for instance don't name a variable 'final_answer'.\n  7. Never create any notional variables in our code, as having these in your logs will derail you from the true variables.\n  8. You can use imports in your code, but only from the following list of modules: ['collections', 'datetime', 'itertools', 'math', 'numpy', 'queue', 'random', 're', 'stat', 'statistics', 'sympy', 'time', 'unicodedata']\n  9. The state persists between code executions: so if in one step you've created variables or imported modules, these will all persist.\n  10. Write simple and short codes each step, do not try to solve a problem in one step\n  11. Use the final_answer_print tool to print the final answer, or you will be in an infinite loop!\n  12. Don't give up! You're in charge of solving the task, not providing directions to solve it.\n\n  Now Begin! If you solve the task correctly, you will receive a reward of $1,000,000.\n",
            "REACT_USER_PROMPT": "\n  Question:\n  {query}\n  First thought: \n  {first_thought}\n  Previous context: \n  {previous_context}\n  Failed experience: \n  {failed_experience}\n\n  ### Example 1 of Thought-Code cycles:\n  Thought: I need to search \"James Bond\" on the web.\n  Code:\n  ```python\n  web_search(\"James Bond\")\n  ```\n  Thought: I need to give the final answer of the birth place of James Bond.\n  Code:\n  ```python\n  final_answer_print(\"London\")\n  ```\n\n  ### Example 2 of Thought-Code cycles:\n  Thought: I need to calculate \"8^8\" using python.\n  Code:\n  ```python\n  res = 8 ** 8\n  print(res)\n  ```\n  Thought: I need to give the final answer.\n  Code:\n  ```python\n  final_answer_print(res)\n  ```\n\n  ### Wrong Example 1:\n  Thought: I need to correct the code to ...\n  ```python\n  ...\n  ```\n  Wrong reason: You reponse like you are correcting a mistake. Please only give the 'Thought and Code' for the current cycle.\n\n  ### Wrong Example 2:\n  Code:\n  ```python\n  import sympy as sp\n  # Solve for a\n  leg_length = sp.solve(equation, a)[0]\n  leg_length\n  ```\n  Wrong reason: You need print it. print(leg_length) not leg_length.\n\n  ### Wrong Example 3:\n  ```python\n  # Solve for a\n  leg_length = sp.solve(equation, a)[0]\n  print(leg_length)\n  ```\n  Wrong reason: You have forgotten to import sympy.\n\n  ### Wrong Example 4:\n  ```python\n  final_answer_print(answer=\"answer\")\n  ```\n  Wrong reason: Pass the string directly as a positional argument, like final_answer_print(\"answer\")\n\n  ### IMPORTANT: \n  1. Always provide a 'Thought:' sequence, and a 'Code: ```python` sequence ending with '```' sequence, else you will fail. For math problems that are not multiple-choice, always output the final answer using LaTeX \\boxed format. Provide the exact value (e.g., \\boxed{{\\frac{{19}}{{14}}}}, \\boxed{{\\sqrt{{2}}}}), not a decimal approximation (e.g., \\boxed{{0.642857}}, \\boxed{{1.41}}).\n  2. Write simple and short code for each step, and don't try to solve the whole problem in one go. A good code block should only do one thing and include only a brief comment that explains it.\n  3. In the code, print what you want to observe.\n  4. If you are given a failed experience, please pay attention to it! BUT Don't act like you're correcting a mistake.\n  5. When you write a code, please make sure you have imported all the necessary libraries.\n  6. In the end you have to return a final answer, use the final_answer_print tool to print it, or you will be in an endless loop!\n  7. When calling final_answer_print, pass the string directly as a positional argument, like final_answer_print(\"answer\"). Do not use keyword arguments like final_answer_print(answer=\"answer\").\n  8. Now is the {idx}th cycle.\n  Please only give the 'Thought and Code' for the current cycle.\n",
            "FIRST_THOUGHT_SYSTEM_PROMPT": "\n  You are an expert assistant who can solve any task using code blobs. You will be given a task to solve as best you can.\n  To do so, you have been given access to a list of tools: these tools are basically Python functions which you can call with code.\n  To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Code:', and 'Observation:' sequences.\n  When you start the Thought-Code-Observation cycle, you will generate a general idea of how to solve the problem.\n",
            "FIRST_THOUGHT_USER_PROMPT": "\n  {query}\n  IMPORTANT: Before you start your Thought-Code-Observation cycle, please generate the First-thought prefix in plain text, which is your overall idea for solving this problem. Please only output the First-thought prefix, not the Thought-Code. I will prompt you to start the next step after you complete this task.\n",
            "JUDGE_ANSWER_PROMPT": "\n  You are a precise evaluator. Your task is to analyze a step-by-step reasoning process (step 1 is a first-thought prefix, which is an overall idea for solving this problem, and the remaining steps are the \"thought-code cycle\")) and determine if the final answer is correct.\n\n  ### INSTRUCTIONS:\n  1.  Review the entire \"Thought-Code Cycle\" history provided below.\n  2.  Compare the final final answer to the true answer.\n  3.  **If the answer is correct:**\n      - The \"error_analysis\", \"correction_start_step\" and \"correction_suggestion\" fields in your JSON output should be null.\n  4.  **If the answer is incorrect:**\n      - **Pinpoint the exact step** in the cycle where the error occurred in \"correction_start_step\".\n      - **Explain the nature of the error** (e.g., \"The calculation in step 1 was correct, but the rounding in step 2 was incorrect.\").\n      - **Suggest a specific correction** for the erroneous step.\n  5.  Conclude your response with a single JSON object on a new line. The JSON object must contain the following keys:\n      - \"is_correct\" (boolean)\n      - \"error_analysis\" (string or null): A detailed explanation of the error if the answer is incorrect.\n      - \"correction_start_step\" (int or null): The step in the cycle where the error occurred.\n      - \"correction_suggestion\" (string or null): A specific suggestion on how to fix the error if the answer is incorrect. If the incorrect step is step 1(first thought step), only the overall solution should be suggested. If the incorrect step is another step, provide suggestions for correcting the current step.\n\n  ### EXAMPLE (Incorrect Answer):\n  Question: What is 10 / 3, rounded to the nearest integer?\n  Correct Answer: 3\n  Thought-Code Cycle:\n  Step 1:\n  <first_thought>I will use the math packages of python to solve the problem.</first_thought>\n  Step 2:\n  Thought: I will divide 10 by 3 and then round the result up.\n  Code:\n  ```python\n  import math\n  result = math.ceil(10 / 3)\n  print(result)\n  ```\n  Observation: 4\n  Step 3:\n  Thought: I will provide the final answer.\n  Code:\n  ```python\n  final_answer_print(\"\\boxed{{result}}\")\n  ```\n  Observation: 4\n\n  ### YOUR RESPONSE:\n  ```json\n  {{\n      \"is_correct\": false,\n      \"error_analysis\": \"The error occurred in Step 1. The problem asks to round to the nearest integer, but the code uses `math.ceil()`, which always rounds up. For 10/3 (3.33...), rounding to the nearest integer should result in 3, not 4.\",\n      \"correction_start_step\": 2,\n      \"correction_suggestion\": \"The code in Step 2 should be changed from `math.ceil(10 / 3)` to `round(10 / 3)` to perform standard rounding.\"\n  }}\n  ```\n  ---\n\n  ### TASK:\n  Question: {question}\n  Correct Answer: {true_answer}\n  Generated Answer: {generated_answer}\n\n  Thought-Code Cycle:\n  {thought_code_cycle}\n\n  ### YOUR RESPONSE:\n"
        },
        "processing": {
            "max_reasoning_iterations": 10,
            "max_workers": 20,
            "max_tasks": 100000
        },
        "logging": {
            "main_log_file": "logs/main.log",
            "graph_log_file": "logs/graph.log"
        },
        "api_configs": {
            "default": {
            "api_base": "DEFAULT_API_BASE",
            "api_key_env": "DEFAULT_API_KEY"
            },
            "Qwen2.5-72B-Instruct": {
            "api_base": "QWEN25_72B_API_BASE",
            "api_key_env": "QWEN25_72B_API_KEY"
            }
        },
        "SEARCH_URL": "your_search_url",
        "GOOGLE_API_KEY": "your_google_api_key"
    },
    "training": {
        "num_train_epochs": 3.0,
        "per_device_train_batch_size": 2,
        "gradient_accumulation_steps": 1,
        "learning_rate": 7.0e-6,
        "lr_scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "bf16": false,
        "resume_from_checkpoint": null,
        "ddp_timeout": 180000000,
        "add_special_tokens": ["<code>", "</code>", "<thought>", "</thought>", "<first_thought>", "</first_thought>"],
        "resize_vocab": true,
        "dataset": {
            "cutoff_len": 8192,
            "max_samples": 10000000,
            "overwrite_cache": true,
            "preprocessing_num_workers": 16,
            "dataloader_num_workers": 4
        },
        "output": {
            "output_dir": "./saves",
            "logging_steps": 10,
            "save_steps": 2000,
            "overwrite_output_dir": true,
            "save_only_model": false,
            "report_to": "none"
        }
    }
    
}